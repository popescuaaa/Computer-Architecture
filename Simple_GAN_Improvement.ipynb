{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple GAN Improvement.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVnfn3ku4bYhpUZ2uR6sfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/popescuaaa/Computer-Architecture/blob/master/Simple_GAN_Improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FsDYwBxTbwB"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJMPouaGXP22"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHVEjHYWwBX"
      },
      "source": [
        "config = {\n",
        "  'learning_rate': 0.1,\n",
        "\n",
        "  'g': {\n",
        "      'dim_latent': 128, # z dimension for generator\n",
        "      'dim_hidden': 128, # size of the hidden layer\n",
        "  },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRSZV-U4Xtn9"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T76bkXbXwwW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WokFzgMXjiO"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3VbVBUMXjK-"
      },
      "source": [
        "# TODO: norm layer why ?\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    __module_list = [\n",
        "        nn.Linear(cfg['dim_latent'], cfg['dim_hidden']),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(cfg['dim_hidden'], cfg['dim_hidden'] * 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(cfg['dim_hidden'] * 2,  28 * 28), # size of a mnist sample\n",
        "        nn.ReLU()\n",
        "    ]\n",
        "\n",
        "    # like a running container => in sequence\n",
        "    self.__net = nn.Sequential(*__module_list)\n",
        "\n",
        "  def forward(self, x):\n",
        "     return self.__net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51_YsZ26XnWr"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uTfdFRtXSjG"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, dim_input, dim_output):\n",
        "    super().__init__()\n",
        "    __module_list = [\n",
        "        nn.Linear(dim_input, dim_input // 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_input // 2, dim_input // 4),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_input // 4, dim_output),\n",
        "        nn.Sigmoid() # Must be signmoid or smth that returns a vlue in [0, 1] to\n",
        "                    # make the BCELoss work\n",
        "    ]\n",
        "\n",
        "    self.__net = nn.Sequential(*__module_list)\n",
        "\n",
        "  def forward(self, x):\n",
        "     return self.__net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IcJF577Xypj"
      },
      "source": [
        "# System training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSs2uzMBdhh"
      },
      "source": [
        "## Parameters and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjy2BL8EB4LE"
      },
      "source": [
        "env_learning_rate = config['learning_rate']\n",
        "\n",
        "g_cfg = config['g']\n",
        "\n",
        "g = Generator(g_cfg)\n",
        "d = Discriminator(28 * 28, 1) # we must generate a score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnWGsfUXNz1"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SskAyb4WX0lQ"
      },
      "source": [
        "batch_size = 32\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
        ")\n",
        "\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_raH-Q7BmB_"
      },
      "source": [
        "optimizer_G = optim.Adam(g.parameters(), lr=config['learning_rate'])\n",
        "optimizer_D = optim.Adam(d.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74RezgxaYgU7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wazi_QJaYfaM"
      },
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (real, _) in enumerate(loader):\n",
        "    \n",
        "    real = real.view(-1, 784)\n",
        "    batch_size = real.shape[0]\n",
        "\n",
        "    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "    noise = torch.randn(batch_size, config['g']['dim_latent'])\n",
        "\n",
        "    fake = g(noise)\n",
        "\n",
        "    disc_real = d(real).view(-1)\n",
        "\n",
        "\n",
        "    lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "\n",
        "    disc_fake = d(fake).view(-1)\n",
        "\n",
        "    lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "\n",
        "    lossD = (lossD_real + lossD_fake) / 2\n",
        "    \n",
        "    d.zero_grad()\n",
        "\n",
        "    lossD.backward(retain_graph=True)\n",
        "\n",
        "    optimizer_D.step()\n",
        "\n",
        "    ### Train Generator: min log(1 - D(G(z)) => max log(D(G(z)))\n",
        "\n",
        "    output = d(fake).view(-1)\n",
        "\n",
        "    lossG = criterion(output, torch.ones_like(output))\n",
        "\n",
        "    g.zero_grad()\n",
        "\n",
        "    lossG.backward()\n",
        "\n",
        "    optimizer_G.step()\n",
        "\n",
        "    if batch_idx == 0:\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFHxJbYFgJtK"
      },
      "source": [
        "## Result\n",
        "\n",
        "\n",
        "```\n",
        "Epoch [0/10] Batch 0/1875                   Loss D: 0.6815, loss G: 0.0000\n",
        "Epoch [1/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [2/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [3/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [4/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [5/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pybx6lqPa_9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}